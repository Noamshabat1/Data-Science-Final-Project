# -*- coding: utf-8 -*-
"""FinalProjectML-Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F1RyRDixNz1uqm-vxUqi3tAWz0G2shyt
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
elon_tsla_models.py
===================
Model-training pipeline for the â€œElon-tweets â†’ TSLA intraday impactâ€ project.

Assumes EDA has produced the following files in â€¦/clean Data/ :
    â€¢ clean_all_musk_posts.csv
    â€¢ clean_tesla_prices_panel.csv
    â€¢ merged_tweets_prices.csv      (optional â€” re-created if absent)

Outputs: none on disk (plots + console only).  Edit as needed.
"""
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os, warnings, re
from typing import List, Tuple, Dict

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.linear_model import Ridge
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV, TimeSeriesSplit
from sklearn.metrics import (mean_squared_error, r2_score,
                             precision_recall_curve,
                             accuracy_score, precision_score,
                             recall_score, f1_score, roc_auc_score,
                             RocCurveDisplay, ConfusionMatrixDisplay)

from xgboost import XGBClassifier

warnings.filterwarnings("ignore")
plt.style.use("ggplot")
RANDOM_STATE = 42

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR  = (
    "/content/drive/My Drive/Notability/Year 4/Second semester/Data Science/Final Project/Data"
)
CLEAN_DIR = f"{BASE_DIR}/clean Data"          # â† same as EDA script

TWEETS_CSV  = f"{CLEAN_DIR}/clean_all_musk_posts.csv"
PRICES_CSV  = f"{CLEAN_DIR}/clean_tesla_prices_panel.csv"
MERGED_CSV  = f"{CLEAN_DIR}/merged_tweets_prices.csv"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
KEYWORDS: List[str] = [
    "model 3","model y","cybertruck","ai",
    "robot","teslabot","fsd","tesla energy","spacex",
]
RET_WINDOWS = [5, 30, 60]

XGB_PARAMS: Dict[str, object] = {
    "n_estimators": 400,
    "learning_rate": 0.03,
    "max_depth": 5,
    "subsample": 0.8,
    "colsample_bytree": 0.8,
    "objective": "binary:logistic",
    "eval_metric": "logloss",
    "random_state": RANDOM_STATE,
    "n_jobs": -1,
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Mini helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def banner(txt): print(f"\n{'â”€'*60}\n{txt}\n{'â”€'*60}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Data loaders  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_clean_sets() -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    tweets  = pd.read_csv(TWEETS_CSV,  parse_dates=["created_at"])
    prices  = pd.read_csv(PRICES_CSV,  index_col=0, parse_dates=True)
    if os.path.exists(MERGED_CSV):
        merged = pd.read_csv(MERGED_CSV, parse_dates=["datetime"])
    else:                      # fallback: rebuild merge quickly
        banner("âš  merged_tweets_prices.csv missing â€” rebuilding")
        tw = tweets.copy()
        tw["ts_min"] = pd.to_datetime(tw["created_at"], utc=True)\
                          .dt.tz_localize(None).dt.floor("T")
        ret_cols = ["close"] + [f"ret_fwd_{w}m" for w in RET_WINDOWS]
        merged = pd.merge(
            tw, prices[ret_cols], left_on="ts_min",
            right_index=True, how="inner"
        )
        merged["datetime"] = merged["ts_min"]
    return tweets, prices, merged

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ridge baseline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_ridge(df: pd.DataFrame,
              horizon=60,
              alpha_grid=[1e-4,1e-3,1e-2,.1,1,10,100]):
    banner("ğŸ“Š  Baseline â€“ Ridge (+CV)")
    y = df[f"ret_fwd_{horizon}m"].values
    X = df[["sentiment", *[f"kw_{kw.replace(' ','_')}" for kw in KEYWORDS]]].values

    split = int(.7*len(df))
    X_tr, X_te, y_tr, y_te = X[:split], X[split:], y[:split], y[split:]

    pipe = Pipeline([("scale", StandardScaler(with_mean=False)),
                     ("ridge", Ridge(random_state=RANDOM_STATE))])
    cv   = TimeSeriesSplit(n_splits=5)
    gscv = GridSearchCV(pipe, {"ridge__alpha":alpha_grid},
                        cv=cv, scoring="neg_mean_squared_error", n_jobs=-1)
    gscv.fit(X_tr, y_tr)

    best_a = gscv.best_params_["ridge__alpha"]
    preds  = gscv.predict(X_te)
    rmse   = mean_squared_error(y_te,preds)**.5
    r2     = r2_score(y_te,preds)
    print(f"   Best Î± = {best_a:.4g} | RMSE = {rmse:.6f} | RÂ² = {r2:.4f}")

    plt.figure(figsize=(4,4))
    plt.scatter(y_te,preds,alpha=.3); plt.axline((0,0),slope=1,color="k")
    plt.xlabel("Actual fwd return"); plt.ylabel("Predicted")
    plt.title(f"Ridge (Î±={best_a})"); plt.tight_layout(); plt.show()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ TF-IDF helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _clock_features(ts: pd.Series) -> pd.DataFrame:
    ts = pd.to_datetime(ts, utc=True)
    mins = ts.dt.hour*60+ts.dt.minute
    rad  = 2*np.pi*mins/(24*60)
    rush = (((mins>=9*60)&(mins<10*60))|((mins>=15*60)&(mins<16*60))).astype(int)
    return pd.DataFrame({"tod_sin":np.sin(rad),
                         "tod_cos":np.cos(rad),
                         "rush":rush}, index=ts.index)

def _interactions(base: pd.DataFrame, rush_flag: pd.Series)->pd.DataFrame:
    out={"sent_rush":base["sentiment"]*rush_flag}
    for c in base.columns:
        if c.startswith("kw_"):
            out[f"{c}_rush"] = (base[c].astype(bool)&rush_flag.astype(bool)).astype(int)
    return pd.DataFrame(out,index=base.index)

def build_feature_matrix(df: pd.DataFrame,
                         horizon=60,
                         tfidf_max=400) -> Tuple[pd.DataFrame,pd.Series]:
    from sklearn.feature_extraction.text import TfidfVectorizer
    df = df.dropna(subset=[f"ret_fwd_{horizon}m"]).copy()
    df["target"] = (df[f"ret_fwd_{horizon}m"]>0).astype(int)

    kw_cols=[f"kw_{kw.replace(' ','_')}" for kw in KEYWORDS]
    base=df[["sentiment","text_len",*kw_cols]]
    blocks=[base]

    tv=TfidfVectorizer(max_features=4000,ngram_range=(1,2),min_df=15)
    Xtf=tv.fit_transform(df["clean_text"])
    y=df[f"ret_fwd_{horizon}m"].fillna(0).values
    corrs=np.nan_to_num([np.corrcoef(col.toarray().ravel(),y)[0,1] for col in Xtf.T])
    keep=np.argsort(np.abs(corrs))[-tfidf_max:]
    blocks.append(pd.DataFrame(Xtf[:,keep].toarray(),
                               columns=[f"tfidf_{t}" for t in tv.get_feature_names_out()[keep]],
                               index=df.index))

    ts=df["datetime"] if "datetime" in df.columns else pd.Series(df.index,index=df.index)
    clk=_clock_features(ts); blocks.append(clk); blocks.append(_interactions(base,clk["rush"]))

    X=pd.concat(blocks,axis=1)
    return X, df["target"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ XGBoost trainer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def train_xgb(df,horizon=60,tfidf_max=400):
    banner("ğŸš€  Advanced â€“ XGBoost")
    X,y=build_feature_matrix(df,horizon,tfidf_max)
    split=int(.7*len(X))
    X_tr,X_te,y_tr,y_te=X.iloc[:split],X.iloc[split:],y.iloc[:split],y.iloc[split:]

    params=dict(XGB_PARAMS, scale_pos_weight=(y_tr==0).sum()/max((y_tr==1).sum(),1))
    model=XGBClassifier(**params).fit(X_tr,y_tr,
        eval_set=[(X_tr,y_tr),(X_te,y_te)],
        early_stopping_rounds=50, verbose=False)

    prob_te=model.predict_proba(X_te)[:,1]
    prec,rec,thr=precision_recall_curve(y_te,prob_te)
    f1=2*prec*rec/(prec+rec+1e-8); best=int(f1.argmax()); t=thr[best]
    print(f"â˜… Ï„â‰ˆ{t:.3f} | F1={f1[best]:.3f} | P={prec[best]:.3f} | R={rec[best]:.3f}")

    y_pred=(prob_te>=t).astype(int)
    print(f"Accuracy  : {accuracy_score(y_te,y_pred):.3f}")
    print(f"Precision : {precision_score(y_te,y_pred):.3f}")
    print(f"Recall    : {recall_score(y_te,y_pred):.3f}")
    print(f"ROC AUC   : {roc_auc_score(y_te,prob_te):.3f}")

    RocCurveDisplay.from_predictions(y_te,prob_te); plt.title("ROC â€” XGB"); plt.show()
    ConfusionMatrixDisplay.from_predictions(y_te,y_pred,cmap="viridis"); plt.show()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    banner("ğŸ  MODEL PIPELINE START")
    _,_,merged = load_clean_sets()

    run_ridge(merged,horizon=60)
    train_xgb(merged,horizon=60)

    banner("âœ…  MODEL PIPELINE FINISHED")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Entrypoint â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    main()